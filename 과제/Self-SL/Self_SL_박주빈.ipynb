{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Self-Supervised Learning**"
      ],
      "metadata": {
        "id": "zouFGmBUYFwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **데이터 다운로드**"
      ],
      "metadata": {
        "id": "Qoc5Eg6cYKp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, Subset, Dataset\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 재현성 설정\n",
        "random.seed(2024)\n",
        "np.random.seed(2024)\n",
        "torch.manual_seed(2024)\n",
        "torch.cuda.manual_seed(2024)\n",
        "torch.cuda.manual_seed_all(2024)\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 50\n",
        "SSL_EPOCHS = 100\n",
        "LEARNING_RATE = 0.1\n",
        "SSL_LEARNING_RATE = 0.001\n",
        "TAU = 0.07\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "oycHasuJmRxt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SimCLR용 데이터 변환 (두 개의 Augmentation 생성)\n",
        "class SimCLRTransform:\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(32),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "        ])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.transform(x), self.transform(x)  # 두 개의 서로 다른 변환된 이미지 반환\n",
        "\n",
        "# CIFAR-100 데이터 로드 (Supervised Learning용)\n",
        "supervised_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "\n",
        "dataset = datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=supervised_transform)\n",
        "test_dataset = datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=supervised_transform)\n",
        "\n",
        "# Test DataLoader 생성\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# 레이블 10% 데이터 추출\n",
        "num_classes = 100\n",
        "labeled_indices = []\n",
        "unlabeled_indices = []\n",
        "\n",
        "for class_idx in range(num_classes):\n",
        "    class_indices = np.where(np.array(dataset.targets) == class_idx)[0]\n",
        "    np.random.shuffle(class_indices)\n",
        "    labeled_indices.extend(class_indices[:60])   # 각 클래스당 60개 (10%)\n",
        "    unlabeled_indices.extend(class_indices[60:]) # 나머지 90%\n",
        "\n",
        "# Labeled & Unlabeled Dataset 생성\n",
        "labeled_dataset = Subset(dataset, labeled_indices)\n",
        "\n",
        "# Unlabeled 데이터에 SimCLR Transform 적용\n",
        "unlabeled_dataset = datasets.CIFAR100(root=\"./data\", train=True, download=False, transform=SimCLRTransform())\n",
        "\n",
        "# DataLoader 생성\n",
        "labeled_loader = DataLoader(labeled_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19VSHqSomqyM",
        "outputId": "d662958b-ce9e-4998-fd28-5c4de82ce992"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:03<00:00, 45.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 정의**"
      ],
      "metadata": {
        "id": "U-WFdsTDmBp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet 모델 정의\n",
        "class ResNetBaseline(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNetBaseline, self).__init__()\n",
        "        self.model = models.resnet18(num_classes=100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Supervised Learning 학습 (Baseline)\n",
        "def train_supervised():\n",
        "    model = ResNetBaseline().to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in labeled_loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {total_loss/len(labeled_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "fW682JEImj3o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-Supervised Learning (SimCLR 방식)\n",
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, base_model, out_dim=128):\n",
        "        super(SimCLR, self).__init__()\n",
        "        self.encoder = base_model\n",
        "        self.encoder.fc = nn.Identity()\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        return self.projector(features)\n",
        "\n",
        "# SimCLR 학습 (pretrain)\n",
        "def pretrain_simclr(model, dataloader, epochs=100, lr=0.001, tau=0.07, device=DEVICE):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for (images1, images2), _ in dataloader:\n",
        "            images1, images2 = images1.to(device), images2.to(device) # 동일한 이미지에서 서로 다른 augmentation을 거친 image\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            z1 = model(images1)\n",
        "            z2 = model(images2)\n",
        "\n",
        "            z1 = F.normalize(z1, dim=1)\n",
        "            z2 = F.normalize(z2, dim=1)\n",
        "\n",
        "            features = torch.cat([z1, z2], dim=0)  # (2N, D)\n",
        "\n",
        "            # 유사도 계산\n",
        "            cos_sim = F.cosine_similarity(features[:, None, :], features[None, :, :], dim=-1)\n",
        "\n",
        "            # self-mask를 사용하여 같은 이미지 제거\n",
        "            self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=device)\n",
        "            cos_sim.masked_fill_(self_mask, -9e15)\n",
        "\n",
        "            # positive sample 위치를 결정\n",
        "            pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
        "\n",
        "            # InfoNCE Loss\n",
        "            # Positive Pair는 같은 이미지의 서로 다른 augmentation 결과이고, Negative Pair는 배치 내의 다른 이미지\n",
        "            cos_sim = cos_sim / tau\n",
        "            nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
        "            loss = nll.mean()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss / len(dataloader):.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "-OpCns6amgVZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 학습 및 평가**"
      ],
      "metadata": {
        "id": "4nj1TArfYW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Supervised Model...\")\n",
        "baseline_model = train_supervised()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyx2jKS0mYv4",
        "outputId": "a27ff6b7-6e0e-40a9-b355-d268b2142626"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Supervised Model...\n",
            "Epoch [1/50], Loss: 5.0273, Accuracy: 2.40%\n",
            "Epoch [2/50], Loss: 4.4337, Accuracy: 5.18%\n",
            "Epoch [3/50], Loss: 4.1957, Accuracy: 6.80%\n",
            "Epoch [4/50], Loss: 4.0452, Accuracy: 8.57%\n",
            "Epoch [5/50], Loss: 3.9352, Accuracy: 9.33%\n",
            "Epoch [6/50], Loss: 3.8472, Accuracy: 10.55%\n",
            "Epoch [7/50], Loss: 3.8182, Accuracy: 10.82%\n",
            "Epoch [8/50], Loss: 3.7252, Accuracy: 11.97%\n",
            "Epoch [9/50], Loss: 3.6936, Accuracy: 13.22%\n",
            "Epoch [10/50], Loss: 3.6190, Accuracy: 14.15%\n",
            "Epoch [11/50], Loss: 3.5634, Accuracy: 14.85%\n",
            "Epoch [12/50], Loss: 3.5213, Accuracy: 15.30%\n",
            "Epoch [13/50], Loss: 3.4803, Accuracy: 16.28%\n",
            "Epoch [14/50], Loss: 3.4125, Accuracy: 17.67%\n",
            "Epoch [15/50], Loss: 3.3805, Accuracy: 18.35%\n",
            "Epoch [16/50], Loss: 3.3365, Accuracy: 18.90%\n",
            "Epoch [17/50], Loss: 3.3155, Accuracy: 19.30%\n",
            "Epoch [18/50], Loss: 3.2327, Accuracy: 20.78%\n",
            "Epoch [19/50], Loss: 3.1854, Accuracy: 21.53%\n",
            "Epoch [20/50], Loss: 3.1341, Accuracy: 21.98%\n",
            "Epoch [21/50], Loss: 3.1074, Accuracy: 22.68%\n",
            "Epoch [22/50], Loss: 3.0877, Accuracy: 23.78%\n",
            "Epoch [23/50], Loss: 3.0107, Accuracy: 25.13%\n",
            "Epoch [24/50], Loss: 2.9493, Accuracy: 26.35%\n",
            "Epoch [25/50], Loss: 2.9113, Accuracy: 27.15%\n",
            "Epoch [26/50], Loss: 2.8740, Accuracy: 27.53%\n",
            "Epoch [27/50], Loss: 2.8303, Accuracy: 28.80%\n",
            "Epoch [28/50], Loss: 2.7546, Accuracy: 30.13%\n",
            "Epoch [29/50], Loss: 2.7327, Accuracy: 30.55%\n",
            "Epoch [30/50], Loss: 2.6612, Accuracy: 32.88%\n",
            "Epoch [31/50], Loss: 2.5916, Accuracy: 33.40%\n",
            "Epoch [32/50], Loss: 2.5266, Accuracy: 35.07%\n",
            "Epoch [33/50], Loss: 2.4559, Accuracy: 36.17%\n",
            "Epoch [34/50], Loss: 2.4440, Accuracy: 36.93%\n",
            "Epoch [35/50], Loss: 2.3676, Accuracy: 38.97%\n",
            "Epoch [36/50], Loss: 2.2892, Accuracy: 41.27%\n",
            "Epoch [37/50], Loss: 2.2575, Accuracy: 41.00%\n",
            "Epoch [38/50], Loss: 2.2048, Accuracy: 43.07%\n",
            "Epoch [39/50], Loss: 2.1166, Accuracy: 44.13%\n",
            "Epoch [40/50], Loss: 2.0434, Accuracy: 47.25%\n",
            "Epoch [41/50], Loss: 1.9847, Accuracy: 49.02%\n",
            "Epoch [42/50], Loss: 1.9155, Accuracy: 50.53%\n",
            "Epoch [43/50], Loss: 1.8512, Accuracy: 52.07%\n",
            "Epoch [44/50], Loss: 1.8366, Accuracy: 52.67%\n",
            "Epoch [45/50], Loss: 1.8231, Accuracy: 54.50%\n",
            "Epoch [46/50], Loss: 1.7205, Accuracy: 55.93%\n",
            "Epoch [47/50], Loss: 1.7641, Accuracy: 54.50%\n",
            "Epoch [48/50], Loss: 1.7017, Accuracy: 55.90%\n",
            "Epoch [49/50], Loss: 1.7095, Accuracy: 56.65%\n",
            "Epoch [50/50], Loss: 1.6893, Accuracy: 57.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pretraining SSL Model...\")\n",
        "ssl_encoder = pretrain_simclr(SimCLR(models.resnet18()), unlabeled_loader, epochs=100, lr=SSL_LEARNING_RATE, tau=TAU)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS7A3eZOmceh",
        "outputId": "3d950e3b-3536-4255-86b0-db4c9ef1cd68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretraining SSL Model...\n",
            "Epoch [1/100], Loss: 1.9608\n",
            "Epoch [2/100], Loss: 1.2557\n",
            "Epoch [3/100], Loss: 1.0057\n",
            "Epoch [4/100], Loss: 0.8594\n",
            "Epoch [5/100], Loss: 0.7694\n",
            "Epoch [6/100], Loss: 0.7027\n",
            "Epoch [7/100], Loss: 0.6468\n",
            "Epoch [8/100], Loss: 0.6066\n",
            "Epoch [9/100], Loss: 0.5909\n",
            "Epoch [10/100], Loss: 0.5522\n",
            "Epoch [11/100], Loss: 0.5311\n",
            "Epoch [12/100], Loss: 0.5104\n",
            "Epoch [13/100], Loss: 0.4945\n",
            "Epoch [14/100], Loss: 0.4874\n",
            "Epoch [15/100], Loss: 0.4640\n",
            "Epoch [16/100], Loss: 0.4504\n",
            "Epoch [17/100], Loss: 0.4423\n",
            "Epoch [18/100], Loss: 0.4265\n",
            "Epoch [19/100], Loss: 0.4211\n",
            "Epoch [20/100], Loss: 0.4214\n",
            "Epoch [21/100], Loss: 0.3992\n",
            "Epoch [22/100], Loss: 0.4008\n",
            "Epoch [23/100], Loss: 0.3870\n",
            "Epoch [24/100], Loss: 0.3769\n",
            "Epoch [25/100], Loss: 0.3730\n",
            "Epoch [26/100], Loss: 0.3635\n",
            "Epoch [27/100], Loss: 0.3558\n",
            "Epoch [28/100], Loss: 0.3648\n",
            "Epoch [29/100], Loss: 0.3462\n",
            "Epoch [30/100], Loss: 0.3466\n",
            "Epoch [31/100], Loss: 0.3324\n",
            "Epoch [32/100], Loss: 0.3300\n",
            "Epoch [33/100], Loss: 0.3289\n",
            "Epoch [34/100], Loss: 0.3263\n",
            "Epoch [35/100], Loss: 0.3256\n",
            "Epoch [36/100], Loss: 0.3161\n",
            "Epoch [37/100], Loss: 0.3162\n",
            "Epoch [38/100], Loss: 0.3090\n",
            "Epoch [39/100], Loss: 0.3182\n",
            "Epoch [40/100], Loss: 0.3019\n",
            "Epoch [41/100], Loss: 0.3000\n",
            "Epoch [42/100], Loss: 0.3015\n",
            "Epoch [43/100], Loss: 0.2892\n",
            "Epoch [44/100], Loss: 0.2940\n",
            "Epoch [45/100], Loss: 0.2852\n",
            "Epoch [46/100], Loss: 0.2890\n",
            "Epoch [47/100], Loss: 0.2895\n",
            "Epoch [48/100], Loss: 0.2783\n",
            "Epoch [49/100], Loss: 0.2762\n",
            "Epoch [50/100], Loss: 0.2813\n",
            "Epoch [51/100], Loss: 0.2807\n",
            "Epoch [52/100], Loss: 0.2705\n",
            "Epoch [53/100], Loss: 0.2678\n",
            "Epoch [54/100], Loss: 0.2652\n",
            "Epoch [55/100], Loss: 0.2705\n",
            "Epoch [56/100], Loss: 0.2644\n",
            "Epoch [57/100], Loss: 0.2561\n",
            "Epoch [58/100], Loss: 0.2693\n",
            "Epoch [59/100], Loss: 0.2506\n",
            "Epoch [60/100], Loss: 0.2607\n",
            "Epoch [61/100], Loss: 0.2545\n",
            "Epoch [62/100], Loss: 0.2540\n",
            "Epoch [63/100], Loss: 0.2520\n",
            "Epoch [64/100], Loss: 0.2507\n",
            "Epoch [65/100], Loss: 0.2460\n",
            "Epoch [66/100], Loss: 0.2408\n",
            "Epoch [67/100], Loss: 0.2440\n",
            "Epoch [68/100], Loss: 0.2411\n",
            "Epoch [69/100], Loss: 0.2426\n",
            "Epoch [70/100], Loss: 0.2393\n",
            "Epoch [71/100], Loss: 0.2356\n",
            "Epoch [72/100], Loss: 0.2329\n",
            "Epoch [73/100], Loss: 0.2326\n",
            "Epoch [74/100], Loss: 0.2380\n",
            "Epoch [75/100], Loss: 0.2315\n",
            "Epoch [76/100], Loss: 0.2326\n",
            "Epoch [77/100], Loss: 0.2346\n",
            "Epoch [78/100], Loss: 0.2326\n",
            "Epoch [79/100], Loss: 0.2266\n",
            "Epoch [80/100], Loss: 0.2275\n",
            "Epoch [81/100], Loss: 0.2212\n",
            "Epoch [82/100], Loss: 0.2232\n",
            "Epoch [83/100], Loss: 0.2212\n",
            "Epoch [84/100], Loss: 0.2206\n",
            "Epoch [85/100], Loss: 0.2222\n",
            "Epoch [86/100], Loss: 0.2160\n",
            "Epoch [87/100], Loss: 0.2160\n",
            "Epoch [88/100], Loss: 0.2166\n",
            "Epoch [89/100], Loss: 0.2123\n",
            "Epoch [90/100], Loss: 0.2102\n",
            "Epoch [91/100], Loss: 0.2170\n",
            "Epoch [92/100], Loss: 0.2176\n",
            "Epoch [93/100], Loss: 0.2058\n",
            "Epoch [94/100], Loss: 0.2090\n",
            "Epoch [95/100], Loss: 0.2035\n",
            "Epoch [96/100], Loss: 0.2032\n",
            "Epoch [97/100], Loss: 0.2102\n",
            "Epoch [98/100], Loss: 0.2079\n",
            "Epoch [99/100], Loss: 0.2011\n",
            "Epoch [100/100], Loss: 0.2034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fine-tuning SSL Model...\")\n",
        "ssl_model = train_supervised()"
      ],
      "metadata": {
        "id": "j1Tktfb6mddj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63505e39-9fe6-48cd-e801-d2ab7ad534eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning SSL Model...\n",
            "Epoch [1/50], Loss: 5.0582, Accuracy: 2.32%\n",
            "Epoch [2/50], Loss: 4.4360, Accuracy: 4.70%\n",
            "Epoch [3/50], Loss: 4.2307, Accuracy: 6.00%\n",
            "Epoch [4/50], Loss: 4.0992, Accuracy: 7.12%\n",
            "Epoch [5/50], Loss: 4.0045, Accuracy: 8.33%\n",
            "Epoch [6/50], Loss: 3.9137, Accuracy: 8.88%\n",
            "Epoch [7/50], Loss: 3.8521, Accuracy: 10.32%\n",
            "Epoch [8/50], Loss: 3.7853, Accuracy: 10.83%\n",
            "Epoch [9/50], Loss: 3.7253, Accuracy: 12.40%\n",
            "Epoch [10/50], Loss: 3.6773, Accuracy: 12.95%\n",
            "Epoch [11/50], Loss: 3.6130, Accuracy: 14.28%\n",
            "Epoch [12/50], Loss: 3.5449, Accuracy: 14.92%\n",
            "Epoch [13/50], Loss: 3.4975, Accuracy: 15.90%\n",
            "Epoch [14/50], Loss: 3.4464, Accuracy: 16.70%\n",
            "Epoch [15/50], Loss: 3.3781, Accuracy: 17.63%\n",
            "Epoch [16/50], Loss: 3.3401, Accuracy: 19.08%\n",
            "Epoch [17/50], Loss: 3.2789, Accuracy: 20.12%\n",
            "Epoch [18/50], Loss: 3.2275, Accuracy: 21.92%\n",
            "Epoch [19/50], Loss: 3.1972, Accuracy: 21.43%\n",
            "Epoch [20/50], Loss: 3.1619, Accuracy: 22.47%\n",
            "Epoch [21/50], Loss: 3.1468, Accuracy: 22.12%\n",
            "Epoch [22/50], Loss: 3.0595, Accuracy: 23.85%\n",
            "Epoch [23/50], Loss: 3.0367, Accuracy: 24.12%\n",
            "Epoch [24/50], Loss: 3.0038, Accuracy: 24.92%\n",
            "Epoch [25/50], Loss: 2.9392, Accuracy: 26.33%\n",
            "Epoch [26/50], Loss: 2.9169, Accuracy: 26.45%\n",
            "Epoch [27/50], Loss: 2.8093, Accuracy: 29.15%\n",
            "Epoch [28/50], Loss: 2.7996, Accuracy: 29.47%\n",
            "Epoch [29/50], Loss: 2.7341, Accuracy: 30.63%\n",
            "Epoch [30/50], Loss: 2.6825, Accuracy: 31.53%\n",
            "Epoch [31/50], Loss: 2.5975, Accuracy: 33.78%\n",
            "Epoch [32/50], Loss: 2.5597, Accuracy: 35.22%\n",
            "Epoch [33/50], Loss: 2.5134, Accuracy: 34.75%\n",
            "Epoch [34/50], Loss: 2.4478, Accuracy: 37.07%\n",
            "Epoch [35/50], Loss: 2.3655, Accuracy: 38.98%\n",
            "Epoch [36/50], Loss: 2.3120, Accuracy: 40.83%\n",
            "Epoch [37/50], Loss: 2.2593, Accuracy: 41.45%\n",
            "Epoch [38/50], Loss: 2.1673, Accuracy: 44.30%\n",
            "Epoch [39/50], Loss: 2.1192, Accuracy: 44.98%\n",
            "Epoch [40/50], Loss: 2.0574, Accuracy: 46.95%\n",
            "Epoch [41/50], Loss: 1.9988, Accuracy: 47.78%\n",
            "Epoch [42/50], Loss: 1.9565, Accuracy: 49.63%\n",
            "Epoch [43/50], Loss: 1.8962, Accuracy: 51.57%\n",
            "Epoch [44/50], Loss: 1.8477, Accuracy: 52.48%\n",
            "Epoch [45/50], Loss: 1.7882, Accuracy: 54.50%\n",
            "Epoch [46/50], Loss: 1.7857, Accuracy: 53.95%\n",
            "Epoch [47/50], Loss: 1.7803, Accuracy: 55.40%\n",
            "Epoch [48/50], Loss: 1.7265, Accuracy: 56.22%\n",
            "Epoch [49/50], Loss: 1.7011, Accuracy: 57.07%\n",
            "Epoch [50/50], Loss: 1.7077, Accuracy: 57.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 함수\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Baseline 모델 평가\n",
        "baseline_acc = evaluate_model(baseline_model, test_loader)\n",
        "\n",
        "# SSL 모델 평가\n",
        "ssl_acc = evaluate_model(ssl_model, test_loader)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Baseline Model Test Accuracy: {baseline_acc:.2f}%\")\n",
        "print(f\"SSL Model Test Accuracy: {ssl_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "WcInv_39m-AV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b90e2d3f-5094-4c5a-d95a-d4c732e17078"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Model Test Accuracy: 22.32%\n",
            "SSL Model Test Accuracy: 22.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **분석 및 고찰**\n",
        "\n",
        "### **모델 정의**\n",
        "\n",
        "- **Baseline 모델**: 주어진 ResNet18 모델을 사용하여 10% labeled data만으로 학습하였습니다.\n",
        "\n",
        "- **Self-Supervised Learning**: SimCLR 방식을 사용하여 contrastive pretraining을 수행한 후, 10% labeled data로 fine-tuning 하였습니다.\n",
        "\n",
        "### **데이터셋 준비 (CIFAR-100)**\n",
        "- CIFAR-100은 100개의 클래스를 포함하며, 각 클래스당 600개의 샘플이 존재합니다.\n",
        "- 각 클래스에서 10%에 해당하는 60개 샘플만 선택하여 **labeled dataset**을 구성합니다.\n",
        "- 나머지 540개 샘플은 **unlabeled dataset**으로 저장합니다.\n",
        "- 10% labeled data는 supervised learning과 fine-tuning에 사용했습니다.\n",
        "- 90% unlabeled data는 contrastive learning을 통해 pretraining에 활용했습니다.\n",
        "\n",
        "### **Self-Supervised Learning**\n",
        "- SimCLR 방식으로 **Contrastive Learning**을 수행하여 ResNet18의 Encoder를 Pretraining 하였습니다.\n",
        "\n",
        "### **모델 학습 결과**\n",
        "contrastive learning을 100 epoch로 실행한 결과, test set에 대해 supervised가 더 높은 성능을 보였습니다. **충분한 epoch를 설정하지 않아 train set에 대해서 두 모델 모두 완전히 학습하지 못하는 결과를 초래**했습니다. 아마도 이러한 이유 때문에 결과가 두 모델을 올바르게 비교하는데 부족해보입니다. 두 모델이 완전히 train set에 대해 학습하였을 때, test set accuracy가 어떻게 될지 실험적으로 추후에 확인해보도록 하겠습니다."
      ],
      "metadata": {
        "id": "BlHkQ3efYblZ"
      }
    }
  ]
}