{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Self-Supervised Learning**"
      ],
      "metadata": {
        "id": "zouFGmBUYFwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **데이터 다운로드**"
      ],
      "metadata": {
        "id": "Qoc5Eg6cYKp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, Subset, Dataset\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 재현성 설정\n",
        "random.seed(2024)\n",
        "np.random.seed(2024)\n",
        "torch.manual_seed(2024)\n",
        "torch.cuda.manual_seed(2024)\n",
        "torch.cuda.manual_seed_all(2024)\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 50\n",
        "SSL_EPOCHS = 100\n",
        "LEARNING_RATE = 0.1\n",
        "SSL_LEARNING_RATE = 0.001\n",
        "TAU = 0.07\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "oycHasuJmRxt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SimCLR용 데이터 변환 (두 개의 Augmentation 생성)\n",
        "class SimCLRTransform:\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(32),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "        ])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.transform(x), self.transform(x)  # 두 개의 서로 다른 변환된 이미지 반환\n",
        "\n",
        "# CIFAR-100 데이터 로드 (Supervised Learning용)\n",
        "supervised_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "\n",
        "dataset = datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=supervised_transform)\n",
        "test_dataset = datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=supervised_transform)\n",
        "\n",
        "# Test DataLoader 생성\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# 레이블 10% 데이터 추출\n",
        "num_classes = 100\n",
        "labeled_indices = []\n",
        "unlabeled_indices = []\n",
        "\n",
        "for class_idx in range(num_classes):\n",
        "    class_indices = np.where(np.array(dataset.targets) == class_idx)[0]\n",
        "    np.random.shuffle(class_indices)\n",
        "    labeled_indices.extend(class_indices[:60])   # 각 클래스당 60개 (10%)\n",
        "    unlabeled_indices.extend(class_indices[60:]) # 나머지 90%\n",
        "\n",
        "# Labeled & Unlabeled Dataset 생성\n",
        "labeled_dataset = Subset(dataset, labeled_indices)\n",
        "\n",
        "# Unlabeled 데이터에 SimCLR Transform 적용\n",
        "unlabeled_dataset = datasets.CIFAR100(root=\"./data\", train=True, download=False, transform=SimCLRTransform())\n",
        "\n",
        "# DataLoader 생성\n",
        "labeled_loader = DataLoader(labeled_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19VSHqSomqyM",
        "outputId": "6b98739d-f5dd-48ee-dfcc-6977227bf25b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 정의**"
      ],
      "metadata": {
        "id": "U-WFdsTDmBp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet 모델 정의\n",
        "class ResNetBaseline(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNetBaseline, self).__init__()\n",
        "        self.model = models.resnet18(num_classes=100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Supervised Learning 학습 (Baseline)\n",
        "def train_supervised():\n",
        "    model = ResNetBaseline().to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in labeled_loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {total_loss/len(labeled_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "fW682JEImj3o"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-Supervised Learning (SimCLR 방식)\n",
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, base_model, out_dim=128):\n",
        "        super(SimCLR, self).__init__()\n",
        "        self.encoder = base_model\n",
        "        self.encoder.fc = nn.Identity()\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        return self.projector(features)\n",
        "\n",
        "# SimCLR 학습 (pretrain)\n",
        "def pretrain_simclr(model, dataloader, epochs=100, lr=0.001, tau=0.07, device=DEVICE):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for (images1, images2), _ in dataloader:\n",
        "            images1, images2 = images1.to(device), images2.to(device) # 동일한 이미지에서 서로 다른 augmentation을 거친 image\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            z1 = model(images1)\n",
        "            z2 = model(images2)\n",
        "\n",
        "            z1 = F.normalize(z1, dim=1)\n",
        "            z2 = F.normalize(z2, dim=1)\n",
        "\n",
        "            features = torch.cat([z1, z2], dim=0)  # (2N, D)\n",
        "\n",
        "            # 유사도 계산\n",
        "            cos_sim = F.cosine_similarity(features[:, None, :], features[None, :, :], dim=-1)\n",
        "\n",
        "            # self-mask를 사용하여 같은 이미지 제거\n",
        "            self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=device)\n",
        "            cos_sim.masked_fill_(self_mask, -9e15)\n",
        "\n",
        "            # positive sample 위치를 결정\n",
        "            pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
        "\n",
        "            # InfoNCE Loss\n",
        "            # Positive Pair는 같은 이미지의 서로 다른 augmentation 결과이고, Negative Pair는 배치 내의 다른 이미지\n",
        "            cos_sim = cos_sim / tau\n",
        "            nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
        "            loss = nll.mean()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss / len(dataloader):.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "-OpCns6amgVZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 학습 및 평가**"
      ],
      "metadata": {
        "id": "4nj1TArfYW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Supervised Model...\")\n",
        "baseline_model = train_supervised()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyx2jKS0mYv4",
        "outputId": "dcd655db-7108-4a00-e9c7-ee16ba803368"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Supervised Model...\n",
            "Epoch [1/50], Loss: 5.0282, Accuracy: 2.50%\n",
            "Epoch [2/50], Loss: 4.4400, Accuracy: 5.10%\n",
            "Epoch [3/50], Loss: 4.1659, Accuracy: 6.27%\n",
            "Epoch [4/50], Loss: 4.0249, Accuracy: 8.40%\n",
            "Epoch [5/50], Loss: 3.9334, Accuracy: 9.23%\n",
            "Epoch [6/50], Loss: 3.8500, Accuracy: 10.63%\n",
            "Epoch [7/50], Loss: 3.8266, Accuracy: 11.15%\n",
            "Epoch [8/50], Loss: 3.7648, Accuracy: 11.53%\n",
            "Epoch [9/50], Loss: 3.7278, Accuracy: 12.25%\n",
            "Epoch [10/50], Loss: 3.6718, Accuracy: 13.37%\n",
            "Epoch [11/50], Loss: 3.6150, Accuracy: 13.37%\n",
            "Epoch [12/50], Loss: 3.5596, Accuracy: 14.53%\n",
            "Epoch [13/50], Loss: 3.5253, Accuracy: 14.82%\n",
            "Epoch [14/50], Loss: 3.4618, Accuracy: 16.45%\n",
            "Epoch [15/50], Loss: 3.4349, Accuracy: 17.32%\n",
            "Epoch [16/50], Loss: 3.3774, Accuracy: 18.35%\n",
            "Epoch [17/50], Loss: 3.3397, Accuracy: 19.05%\n",
            "Epoch [18/50], Loss: 3.2759, Accuracy: 20.27%\n",
            "Epoch [19/50], Loss: 3.2402, Accuracy: 19.93%\n",
            "Epoch [20/50], Loss: 3.1743, Accuracy: 22.07%\n",
            "Epoch [21/50], Loss: 3.1356, Accuracy: 21.97%\n",
            "Epoch [22/50], Loss: 3.1155, Accuracy: 22.73%\n",
            "Epoch [23/50], Loss: 3.0444, Accuracy: 23.97%\n",
            "Epoch [24/50], Loss: 3.0005, Accuracy: 25.03%\n",
            "Epoch [25/50], Loss: 2.9619, Accuracy: 25.73%\n",
            "Epoch [26/50], Loss: 2.9125, Accuracy: 26.98%\n",
            "Epoch [27/50], Loss: 2.8721, Accuracy: 27.67%\n",
            "Epoch [28/50], Loss: 2.8198, Accuracy: 28.40%\n",
            "Epoch [29/50], Loss: 2.7749, Accuracy: 29.75%\n",
            "Epoch [30/50], Loss: 2.7003, Accuracy: 30.80%\n",
            "Epoch [31/50], Loss: 2.6210, Accuracy: 33.08%\n",
            "Epoch [32/50], Loss: 2.5750, Accuracy: 34.10%\n",
            "Epoch [33/50], Loss: 2.5117, Accuracy: 35.42%\n",
            "Epoch [34/50], Loss: 2.4694, Accuracy: 35.87%\n",
            "Epoch [35/50], Loss: 2.4093, Accuracy: 37.12%\n",
            "Epoch [36/50], Loss: 2.3251, Accuracy: 39.08%\n",
            "Epoch [37/50], Loss: 2.3027, Accuracy: 39.57%\n",
            "Epoch [38/50], Loss: 2.2378, Accuracy: 41.80%\n",
            "Epoch [39/50], Loss: 2.1663, Accuracy: 43.40%\n",
            "Epoch [40/50], Loss: 2.0924, Accuracy: 45.67%\n",
            "Epoch [41/50], Loss: 2.0482, Accuracy: 46.50%\n",
            "Epoch [42/50], Loss: 1.9597, Accuracy: 49.35%\n",
            "Epoch [43/50], Loss: 1.8984, Accuracy: 50.97%\n",
            "Epoch [44/50], Loss: 1.8782, Accuracy: 51.87%\n",
            "Epoch [45/50], Loss: 1.8608, Accuracy: 53.07%\n",
            "Epoch [46/50], Loss: 1.7602, Accuracy: 54.97%\n",
            "Epoch [47/50], Loss: 1.8044, Accuracy: 55.18%\n",
            "Epoch [48/50], Loss: 1.7515, Accuracy: 55.03%\n",
            "Epoch [49/50], Loss: 1.7527, Accuracy: 56.32%\n",
            "Epoch [50/50], Loss: 1.7324, Accuracy: 56.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pretraining SSL Model...\")\n",
        "ssl_encoder = pretrain_simclr(SimCLR(models.resnet18()), unlabeled_loader, epochs=SSL_EPOCHS, lr=SSL_LEARNING_RATE, tau=TAU)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS7A3eZOmceh",
        "outputId": "492ecac2-e56c-43ac-c9e4-20ea64864fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretraining SSL Model...\n",
            "Epoch [1/100], Loss: 1.9321\n",
            "Epoch [2/100], Loss: 1.2230\n",
            "Epoch [3/100], Loss: 0.9996\n",
            "Epoch [4/100], Loss: 0.8623\n",
            "Epoch [5/100], Loss: 0.7896\n",
            "Epoch [6/100], Loss: 0.7269\n",
            "Epoch [7/100], Loss: 0.6884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fine-tuning SSL Model...\")\n",
        "ssl_model = train_supervised()"
      ],
      "metadata": {
        "id": "j1Tktfb6mddj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 함수\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Baseline 모델 평가\n",
        "baseline_acc = evaluate_model(baseline_model, test_loader)\n",
        "\n",
        "# SSL 모델 평가\n",
        "ssl_acc = evaluate_model(ssl_model, test_loader)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Baseline Model Test Accuracy: {baseline_acc:.2f}%\")\n",
        "print(f\"SSL Model Test Accuracy: {ssl_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "WcInv_39m-AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **분석 및 고찰**\n",
        "\n",
        "### **모델 정의**\n",
        "\n",
        "- **Baseline 모델**: 주어진 ResNet18 모델을 사용하여 10% labeled data만으로 학습하였습니다.\n",
        "\n",
        "- **Self-Supervised Learning**: SimCLR 방식을 사용하여 contrastive pretraining을 수행한 후, 10% labeled data로 fine-tuning 하였습니다.\n",
        "\n",
        "### **데이터셋 준비 (CIFAR-100)**\n",
        "- CIFAR-100은 100개의 클래스를 포함하며, 각 클래스당 600개의 샘플이 존재합니다.\n",
        "- 각 클래스에서 10%에 해당하는 60개 샘플만 선택하여 **labeled dataset**을 구성합니다.\n",
        "- 나머지 540개 샘플은 **unlabeled dataset**으로 저장합니다.\n",
        "- 10% labeled data는 supervised learning과 fine-tuning에 사용했습니다.\n",
        "- 90% unlabeled data는 contrastive learning을 통해 pretraining에 활용했습니다.\n",
        "\n",
        "### **Self-Supervised Learning**\n",
        "- SimCLR 방식으로 **Contrastive Learning**을 수행하여 ResNet18의 Encoder를 Pretraining 하였습니다.\n",
        "\n",
        "### **모델 학습 결과**\n",
        "충분한 epoch를 설정하지 않아 train set에 대해서도 완전히 학습하지 못하는 결과를 초래했습니다. 하지만, 성능을 올리는 과제가 아닌 동일한 환경에서 self-supervised learning의 성능을 평가하기 위한 과제이기 때문에 추가적인 학습을 진행하진 않았습니다.\n"
      ],
      "metadata": {
        "id": "BlHkQ3efYblZ"
      }
    }
  ]
}