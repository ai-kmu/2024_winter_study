{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **0. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import**\n",
        "\n",
        "hugging face ì˜ ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ ì•„ë˜ì™€ ê°™ì€ ëª¨ë“ˆë“¤ì„ import í•´ì¤€ë‹¤.\n",
        "\n",
        "**transformers** : Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ë‹¤ì–‘í•œ ì‚¬ì „ í•™ìŠµëœ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸(GPT, BERT, T5 ë“±)ì„ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¤ê³  íŒŒì¸íŠœë‹í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤.\n",
        "ì£¼ìš” ê¸°ëŠ¥: ëª¨ë¸ ë¡œë“œ, í† í¬ë‚˜ì´ì €, í•™ìŠµ, ì¶”ë¡ \n",
        "\n",
        "**datasets** : Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ.\n",
        "datasets.load_dataset()ì„ ì´ìš©í•´ì„œ ë‹¤ì–‘í•œ ê³µê°œ ë°ì´í„°ì…‹(KorQuAD, SQuAD, IMDB ë“±)ì„ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìœ¼ë©°.\n",
        "ë°ì´í„° ë¡œë”©, ì „ì²˜ë¦¬, ë³€í™˜, ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬ ë“±ì„ ì§€ì›í•œë‹¤.\n",
        "\n",
        "**wandb** : ë¨¸ì‹ ëŸ¬ë‹ ì‹¤í—˜ì„ ì¶”ì , ë¡œê¹…í•˜ê³  ì‹œê°í™”í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë¡œ\n",
        "í•™ìŠµ ê³¼ì •ì—ì„œ ì†ì‹¤(loss), ì •í™•ë„(accuracy) ë“±ì„ ì €ì¥í•˜ê³  ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
        "wandb.init()ì„ ì‚¬ìš©í•´ì„œ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•˜ê³  í•™ìŠµ ë¡œê·¸ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤."
      ],
      "metadata": {
        "id": "twNTyVPvPFqb"
      },
      "id": "twNTyVPvPFqb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "568a544d-3d62-49a3-b033-d388fe9380ea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-23T15:58:58.765387Z",
          "iopub.status.busy": "2025-02-23T15:58:58.764734Z",
          "iopub.status.idle": "2025-02-23T15:59:04.817307Z",
          "shell.execute_reply": "2025-02-23T15:59:04.815449Z",
          "shell.execute_reply.started": "2025-02-23T15:58:58.765328Z"
        },
        "id": "568a544d-3d62-49a3-b033-d388fe9380ea",
        "outputId": "fce1ef97-be89-44cd-f6b3-db3599bf2b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in indexes: http://repo.ai.gato/registry/repository/pypi-proxy/simple\n",
            "Requirement already satisfied: transformers in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (4.49.0)\n",
            "Requirement already satisfied: datasets in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (3.3.2)\n",
            "Requirement already satisfied: wandb in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (0.19.7)\n",
            "Requirement already satisfied: filelock in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/gatoai/python/venv/pytorch-2.6.0-cuda12.4-py3.10/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: xxhash in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Using cached http://repo.ai.gato/registry/repository/pypi-proxy/packages/fsspec/2024.12.0/fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/gatoai/python/venv/pytorch-2.6.0-cuda12.4-py3.10/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/gatoai/python/venv/pytorch-2.6.0-cuda12.4-py3.10/lib/python3.10/site-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from wandb) (7.0.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from wandb) (70.3.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/gatoai/python/venv/pytorch-2.6.0-cuda12.4-py3.10/lib/python3.10/site-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/gatoai/python/venv/pytorch-2.6.0-cuda12.4-py3.10/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/gatoai/python/venv/pytorch-2.6.0-cuda12.4-py3.10/lib/python3.10/site-packages (from requests->transformers) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/gatoai/python/venv/pytorch-2.6.0-cuda12.4-py3.10/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/gatoai/python/venv/jupyter-4.3.5-py3.10/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Installing collected packages: fsspec\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.12.0 requires numba-cuda<0.0.18,>=0.0.13, which is not installed.\n",
            "s3fs 2025.2.0 requires fsspec==2025.2.0.*, but you have fsspec 2024.12.0 which is incompatible.\n",
            "cudf-cu12 24.12.0 requires pyarrow<19.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 19.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. ë°ì´í„° ì „ì²˜ë¦¬**\n",
        "\n",
        "KorQuAD ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  KLUE-BERTë¥¼ ì‚¬ìš©í•˜ì—¬ í† í°í™”í•œ í›„, í›ˆë ¨ì„ ìœ„í•œ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì´ë‹¤.  \n",
        "\n",
        "### **ì „ì²˜ë¦¬ ê³¼ì •**\n",
        "1. **context + questionì„ BERT í† í¬ë‚˜ì´ì €ë¡œ í† í°í™”** (**512 í† í° ì œí•œ**)  \n",
        "2. **ì •ë‹µ(Answer)ì˜ ë¬¸ì ìœ„ì¹˜ â†’ í† í° ìœ„ì¹˜ë¡œ ë³€í™˜**  \n",
        "3. **start_positions, end_positionsë¥¼ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì´ í›ˆë ¨í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜**  \n",
        "\n",
        "> ë‚˜ëŠ” **Encoder ê¸°ë°˜ì˜ BERT ëª¨ë¸**ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, `answer`ë¥¼ ìƒì„±í•˜ëŠ” **ìƒì„±í˜•(Generative) ëª¨ë¸**ë“¤ê³¼ëŠ” ë‹¬ë¦¬, ë¬¸ì¥ì˜ **ì‹œì‘, ë ìœ„ì¹˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹**ìœ¼ë¡œ ëª¨ë¸ì„ êµ¬ì„±í–ˆë‹¤.\n"
      ],
      "metadata": {
        "id": "7Hqsfl7eQR55"
      },
      "id": "7Hqsfl7eQR55"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5de760e6-ab05-4e3d-aeae-e6d5bcf177d9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-23T15:59:04.820854Z",
          "iopub.status.busy": "2025-02-23T15:59:04.819867Z",
          "iopub.status.idle": "2025-02-23T15:59:25.477379Z",
          "shell.execute_reply": "2025-02-23T15:59:25.476217Z",
          "shell.execute_reply.started": "2025-02-23T15:59:04.820775Z"
        },
        "id": "5de760e6-ab05-4e3d-aeae-e6d5bcf177d9"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "dataset = load_dataset(\"KorQuAD/squad_kor_v1\")\n",
        "\n",
        "# ì‚¬ìš©í•  ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì„ íƒ (KLUE BERT ì‚¬ìš©)\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
        "def preprocess_function(examples):\n",
        "    inputs = tokenizer(\n",
        "        examples[\"context\"],\n",
        "        examples[\"question\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,\n",
        "    )\n",
        "\n",
        "    # ì •ë‹µ(Answer)ì˜ ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, answer in enumerate(examples[\"answers\"]):\n",
        "        if len(answer[\"text\"]) == 0:  # ì •ë‹µì´ ì—†ëŠ” ê²½ìš°\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            start_char = answer[\"answer_start\"][0]  # ì •ë‹µì˜ ì‹œì‘ ìœ„ì¹˜ (ë¬¸ì ê¸°ì¤€)\n",
        "            end_char = start_char + len(answer[\"text\"][0])  # ì •ë‹µì˜ ë ìœ„ì¹˜\n",
        "\n",
        "            # ì •ë‹µì´ `input_ids` ë‚´ ì–´ëŠ í† í°ì— í•´ë‹¹í•˜ëŠ”ì§€ ì°¾ê¸°\n",
        "            token_start_index = inputs.char_to_token(i, start_char)\n",
        "            token_end_index = inputs.char_to_token(i, end_char - 1)\n",
        "\n",
        "            if token_start_index is None or token_end_index is None:\n",
        "                start_positions.append(0)\n",
        "                end_positions.append(0)\n",
        "            else:\n",
        "                start_positions.append(token_start_index)\n",
        "                end_positions.append(token_end_index)\n",
        "\n",
        "    # ìµœì¢… ë°ì´í„°ì…‹ ë°˜í™˜\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs\n",
        "\n",
        "\n",
        "# ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì ìš©\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "# ë°ì´í„° í˜•ì‹ ë³€í™˜ (Trainerê°€ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •)\n",
        "tokenized_datasets.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"start_positions\", \"end_positions\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. í›ˆë ¨ ë° í‰ê°€**\n",
        "\n",
        "ì´ ì½”ë“œëŠ” Trainerë¥¼ ì‚¬ìš©í•˜ì—¬ KLUE-BERTë¥¼ KorQuAD ë°ì´í„°ì…‹ì— íŒŒì¸íŠœë‹í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ êµ¬ì„±ì„ ë³´ë©´ í¬ê²Œ 3ë‹¨ê³„ë¡œ ë‚˜ë‰œë‹¤.\n",
        "1. ì§ˆë¬¸-ë‹µë³€(Task)ì— íŠ¹í™”ëœ BERT ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë¡œë“œí•œë‹¤.\n",
        "2. trainingArgumentsë¥¼ ì‚¬ìš©í•´ í›ˆë ¨ ì„¤ì • (í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, ë¡œê¹… ë“±)\n",
        "3. Trainerë¥¼ ì‚¬ìš©í•´ ëª¨ë¸, ë°ì´í„°ì…‹, í† í¬ë‚˜ì´ì € ì„¤ì • í›„ í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ\n",
        "\n",
        "**HuggingFace** ê°€ ì œê³µí•˜ëŠ” ì•„ì£¼ ê°„í¸í•œ ë©”ì„œë“œë¥¼ í†µí•´ ëª¨ë¸ì„ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆì—ˆëŠ”ë°, AutoModelForQuestionAnswering ì„ í†µí•´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê²Œ ë˜ë©´, ëª¨ë¸ êµ¬ì¡°ê°€ ìë™ìœ¼ë¡œ QA taskë¥¼ ìœ„í•´ ë§ì¶°ì§€ë©°, ê¸°ì¡´ BERT ëª¨ë¸ì— HEADë¥¼ ë¶™íˆëŠ” ì‹ìœ¼ë¡œ êµ¬í˜„ëœë‹¤. ì¦‰ BACKBORN ì„ ìœ ì§€í•˜ë©´ì„œ, ì¶œë ¥ì„ ë‚¼ ìˆ˜ ìˆëŠ” HEADë¥¼ ìë™ìœ¼ë¡œ ë¶™íˆëŠ”"
      ],
      "metadata": {
        "id": "mRhwmvtzSq7R"
      },
      "id": "mRhwmvtzSq7R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1509868b-18da-40a3-80bc-1e4bec87fb45",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-23T15:59:25.479628Z",
          "iopub.status.busy": "2025-02-23T15:59:25.479167Z",
          "iopub.status.idle": "2025-02-23T15:59:32.104500Z",
          "shell.execute_reply": "2025-02-23T15:59:32.103749Z",
          "shell.execute_reply.started": "2025-02-23T15:59:25.479602Z"
        },
        "id": "1509868b-18da-40a3-80bc-1e4bec87fb45",
        "outputId": "375f7991-d38c-4307-c195-17dc286c975e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/gatoai/python/venv/3.10/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/tmp/ipykernel_7203/608393248.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# í›ˆë ¨ ì„¤ì •\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        "    save_total_limit=2,  # ìµœê·¼ 2ê°œ ëª¨ë¸ë§Œ ì €ì¥\n",
        "    load_best_model_at_end=True,  # ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì €ì¥\n",
        "    report_to=\"wandb\"  # W&B ë¡œê¹…\n",
        ")\n",
        "\n",
        "# Trainer ì •ì˜\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainer í´ë˜ìŠ¤ëŠ” Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” ìë™ í•™ìŠµ ê´€ë¦¬ ë„êµ¬ë¡œ, ì•ì„œ trainerë¥¼ ë§Œë“¤ ë•Œ ì„¤ì •í–ˆë˜ ì„¤ì • ê°’ë“¤ì„ í† ëŒ€ë¡œ trainer í´ë˜ìŠ¤ê°€ í•™ìŠµí•˜ê²Œ ëœë‹¤."
      ],
      "metadata": {
        "id": "NoF1kuCLVLR2"
      },
      "id": "NoF1kuCLVLR2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b57d5fd5-7d35-435a-8582-7042962f772d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-23T15:59:32.105910Z",
          "iopub.status.busy": "2025-02-23T15:59:32.105673Z",
          "iopub.status.idle": "2025-02-23T18:20:06.811402Z",
          "shell.execute_reply": "2025-02-23T18:20:06.810328Z",
          "shell.execute_reply.started": "2025-02-23T15:59:32.105887Z"
        },
        "id": "b57d5fd5-7d35-435a-8582-7042962f772d",
        "outputId": "0233809b-71ad-48a9-f5a0-9edc02261c0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkkk121026\u001b[0m (\u001b[33mkkk121026-kookmin-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "creating run (8.9s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/20203143/wandb/run-20250224_005933-5icmv09l</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kkk121026-kookmin-university/huggingface/runs/5icmv09l' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/kkk121026-kookmin-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/kkk121026-kookmin-university/huggingface' target=\"_blank\">https://wandb.ai/kkk121026-kookmin-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/kkk121026-kookmin-university/huggingface/runs/5icmv09l' target=\"_blank\">https://wandb.ai/kkk121026-kookmin-university/huggingface/runs/5icmv09l</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='37755' max='37755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [37755/37755 2:20:20, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.487700</td>\n",
              "      <td>0.512494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.317100</td>\n",
              "      <td>0.554175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.207800</td>\n",
              "      <td>0.614121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.139400</td>\n",
              "      <td>0.799269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.077400</td>\n",
              "      <td>0.965911</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=37755, training_loss=0.2602638837723144, metrics={'train_runtime': 8434.4087, 'train_samples_per_second': 35.81, 'train_steps_per_second': 4.476, 'total_flos': 7.892076592075776e+16, 'train_loss': 0.2602638837723144, 'epoch': 5.0})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. í•™ìŠµ ì¢…ë£Œ ë° í‰ê°€**\n",
        "\n",
        "í•™ìŠµ ì´í›„ `trainer.evaluate()`ë¥¼ í†µí•´ **validation set**ì— ëŒ€í•œ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìœ¼ë©°,  \n",
        "í•™ìŠµëœ ëª¨ë¸ì˜ **ê°€ì¤‘ì¹˜**ì™€ **í† í¬ë‚˜ì´ì €**ë„ í•¨ê»˜ ì €ì¥í•˜ê²Œ ëœë‹¤.  \n",
        "\n",
        "ë‹¨ìˆœíˆ **loss ê°’ì´ ë‚®ë‹¤**ê³  í•´ì„œ ëª¨ë¸ì´ ì˜ ì‘ë™í•œë‹¤ê³  ë‹¨ì •í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,  \n",
        "ì‹¤ì œë¡œ ëª¨ë¸ì´ **ì˜ˆì¸¡ì„ ì–¼ë§ˆë‚˜ ì˜í•˜ëŠ”ì§€** í™•ì¸í•˜ê¸° ìœ„í•´ **ì„ì˜ì˜ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ ì¶”ë¡ ì„ ìˆ˜í–‰**í–ˆë‹¤.  \n",
        "\n",
        "ì‹¤í—˜ ê²°ê³¼, ì•„ë˜ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì—¬ ëŒ€ë¶€ë¶„ì˜ ì§ˆë¬¸ì— ëŒ€í•´ **ëª¨ë¸ì´ ì˜¬ë°”ë¥´ê²Œ ì¶”ë¡ í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.** ğŸš€  \n",
        "\n",
        "---\n",
        "\n",
        "## **ì‹¤í—˜ ê²°ê³¼ ì˜ˆì‹œ**\n",
        "\n",
        "### ğŸ”¹ **ì˜ˆì œ 1**\n",
        "- **Context:**  \n",
        "  > *í—ˆê¹…í˜ì´ìŠ¤ëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP) ë° ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ í”Œë«í¼ì´ë‹¤. ì£¼ìš” ì œí’ˆìœ¼ë¡œëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìˆë‹¤.*\n",
        "- **Question:**  \n",
        "  > *í—ˆê¹…í˜ì´ìŠ¤ì˜ ì£¼ìš” ì œí’ˆì€ ë¬´ì—‡ì¸ê°€?*\n",
        "- **Answer (Ground Truth):**  \n",
        "  > *íŠ¸ëœìŠ¤í¬ë¨¸ ë¼ì´ë¸ŒëŸ¬ë¦¬*\n",
        "- **Predict (ëª¨ë¸ ì˜ˆì¸¡):**  \n",
        "  > *íŠ¸ëœìŠ¤í¬ë¨¸ ë¼ì´ë¸ŒëŸ¬ë¦¬*\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **ì˜ˆì œ 2**\n",
        "- **Context:**  \n",
        "  > *ì•„ì´ì‘ ë‰´í„´(Isaac Newton)ì€ 17ì„¸ê¸° ì˜êµ­ì˜ ìˆ˜í•™ìì´ì ë¬¼ë¦¬í•™ìë¡œ, ë¯¸ì ë¶„í•™ê³¼ ê³ ì „ì—­í•™ì˜ ê¸°ì´ˆë¥¼ ë‹¤ì¡Œë‹¤. ê·¸ì˜ ì €ì„œ ã€Ší”„ë¦°í‚¤í”¼ì•„(PhilosophiÃ¦ Naturalis Principia Mathematica)ã€‹ëŠ” ë¬¼ë¦¬í•™ ì—­ì‚¬ì—ì„œ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ì±… ì¤‘ í•˜ë‚˜ë¡œ í‰ê°€ë°›ëŠ”ë‹¤*\n",
        "- **Question:**  \n",
        "  > *ì•„ì´ì‘ ë‰´í„´ì€ ì–´ë–¤ í•™ë¬¸ì—ì„œ ì¤‘ìš”í•œ ê¸°ì—¬ë¥¼ í–ˆëŠ”ê°€?*\n",
        "- **Answer (Ground Truth):**  \n",
        "  > *ë¯¸ì ë¶„í•™ê³¼ ê³ ì „ì—­í•™*\n",
        "- **Predict (ëª¨ë¸ ì˜ˆì¸¡):**  \n",
        "  > *ë¯¸ì ë¶„í•™ê³¼ ê³ ì „ì—­í•™*\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **ì˜ˆì œ 2**\n",
        "- **Context:**  \n",
        "  > *ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ë©°, 1ì²œë§Œ ëª…ì´ ë„˜ëŠ” ì¸êµ¬ê°€ ê±°ì£¼í•˜ëŠ” ëŒ€ë„ì‹œì´ë‹¤. ì„œìš¸ì€ ì •ì¹˜, ê²½ì œ, ë¬¸í™”ì˜ ì¤‘ì‹¬ì§€ë¡œì„œ ë‹¤ì–‘í•œ ì—­ì‚¬ì  ìœ ì‚°ê³¼ í˜„ëŒ€ì ì¸ ê±´ì¶•ë¬¼ì´ ê³µì¡´í•˜ëŠ” ê³³ì´ë‹¤*\n",
        "- **Question:**  \n",
        "  > *ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€?*\n",
        "- **Answer (Ground Truth):**  \n",
        "  > *ì„œìš¸*\n",
        "- **Predict (ëª¨ë¸ ì˜ˆì¸¡):**  \n",
        "  > *ì„œìš¸*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "âœ” **ì¶”ê°€ ì‹¤í—˜ì—ì„œë„ ëŒ€ë¶€ë¶„ ì •í™•í•œ ë‹µë³€ì„ ë„ì¶œí•  ìˆ˜ ìˆì—ˆìŒ!**  \n",
        "ğŸ“Œ **í•˜ì§€ë§Œ ì§ê´€ì ìœ¼ë¡œ ë‹µì´ ì£¼ì–´ì§€ì§€ ì•ŠëŠ” ì¼ë¶€ ì–´ë ¤ìš´ ì§ˆë¬¸ì—ì„œëŠ” ë¶€ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê²½ìš°ë„ ìˆì—ˆë‹¤.**\n"
      ],
      "metadata": {
        "id": "O7FIjiA9V0yD"
      },
      "id": "O7FIjiA9V0yD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d64a48a-11be-4140-82f5-8802b5bfbb8b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-23T18:20:06.812907Z",
          "iopub.status.busy": "2025-02-23T18:20:06.812643Z",
          "iopub.status.idle": "2025-02-23T18:20:47.275857Z",
          "shell.execute_reply": "2025-02-23T18:20:47.274734Z",
          "shell.execute_reply.started": "2025-02-23T18:20:06.812884Z"
        },
        "id": "1d64a48a-11be-4140-82f5-8802b5bfbb8b",
        "outputId": "8a1abc10-2cff-422a-aef0-fcc72852797a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='722' max='722' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [722/722 00:40]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Results: {'eval_loss': 0.5124937295913696, 'eval_runtime': 40.4461, 'eval_samples_per_second': 142.758, 'eval_steps_per_second': 17.851, 'epoch': 5.0}\n"
          ]
        }
      ],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation Results: {eval_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a23549f-5a8b-46f4-9545-78c18e253d5f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-23T18:20:47.278487Z",
          "iopub.status.busy": "2025-02-23T18:20:47.278239Z",
          "iopub.status.idle": "2025-02-23T18:21:18.869159Z",
          "shell.execute_reply": "2025-02-23T18:21:18.867096Z",
          "shell.execute_reply.started": "2025-02-23T18:20:47.278466Z"
        },
        "id": "7a23549f-5a8b-46f4-9545-78c18e253d5f",
        "outputId": "f4d7dbd2-c098-41b3-badb-2d970c2514bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved at ./saved_model\n"
          ]
        }
      ],
      "source": [
        "save_path = \"./saved_model\"\n",
        "trainer.save_model(save_path)  # ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥\n",
        "tokenizer.save_pretrained(save_path)  # í† í¬ë‚˜ì´ì €ë„ ì €ì¥\n",
        "\n",
        "print(f\"Model saved at {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35d667e0-c8e1-4652-a3c7-7df6c91ce0c1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T00:28:16.285922Z",
          "iopub.status.busy": "2025-02-24T00:28:16.285210Z",
          "iopub.status.idle": "2025-02-24T00:28:16.330039Z",
          "shell.execute_reply": "2025-02-24T00:28:16.329383Z",
          "shell.execute_reply.started": "2025-02-24T00:28:16.285862Z"
        },
        "id": "35d667e0-c8e1-4652-a3c7-7df6c91ce0c1",
        "outputId": "c3ad7525-e47d-4934-ad22-0eb92fa564c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: ëˆ„ê°€ ê¸°ì¹¨ì†Œë¦¬ë¥¼ ë‚´ì—ˆëŠ”ê°€?\n",
            "Expected Answer: ì˜ì˜ì •\n",
            "Predicted Answer: ì˜ì˜ì •\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "model_name = \"klue/bert-base\"\n",
        "\n",
        "context = \"ê¸°ì¹¨ì†Œë¦¬ë¥¼ ë‚¸ ê²ƒì€ ì˜ì˜ì •ì´ë‹¤.\"\n",
        "question = \"ëˆ„ê°€ ê¸°ì¹¨ì†Œë¦¬ë¥¼ ë‚´ì—ˆëŠ”ê°€?\"\n",
        "expected_answer = \"ì˜ì˜ì •\"  # ì‹¤ì œ ì •ë‹µ\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "inputs = tokenizer(context, question, return_tensors=\"pt\").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "\n",
        "# ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ start, end ì¸ë±ìŠ¤ ì°¾ê¸°\n",
        "start_idx = torch.argmax(start_logits)\n",
        "end_idx = torch.argmax(end_logits)\n",
        "\n",
        "predicted_answer = tokenizer.convert_tokens_to_string(\n",
        "    tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_idx:end_idx+1])\n",
        ")\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Expected Answer: {expected_answer}\")\n",
        "print(f\"Predicted Answer: {predicted_answer}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KorQuAD (Korean Question Answering Dataset) ì†Œê°œ\n",
        "\n",
        "KorQuAD(Korean Question Answering Dataset)ëŠ” í•œêµ­ì–´ ê¸°ê³„ ë…í•´(Machine Reading Comprehension, MRC) íƒœìŠ¤í¬ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ, Hugging Faceì—ì„œëŠ” `\"KorQuAD/squad_kor_v1\"`ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì œê³µë˜ê³  ìˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ 1. KorQuADë€?\n",
        "KorQuADëŠ” í•œêµ­ì–´ ì§ˆë¬¸-ë‹µë³€ íƒœìŠ¤í¬(QA, Question Answering)ë¥¼ í•™ìŠµí•˜ê³  í‰ê°€í•˜ê¸° ìœ„í•´ êµ¬ì¶•ëœ ë°ì´í„°ì…‹ì´ë‹¤. ì´ ë°ì´í„°ì…‹ì€ ì˜ì–´ì˜ ëŒ€í‘œì ì¸ QA ë°ì´í„°ì…‹ì¸ **SQuAD**(Stanford Question Answering Dataset)ë¥¼ ì°¸ê³ í•˜ì—¬ ë§Œë“¤ì–´ì¡Œë‹¤.\n",
        "\n",
        "- **KorQuAD 1.0**: í•œêµ­ì–´ Wikipedia ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ ë¬¸ë‹¨ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±ë¨.\n",
        "- **KorQuAD 2.0**: ì¶”ê°€ì ì¸ ë…¸ì´ì¦ˆ ë°ì´í„°ë¥¼ í¬í•¨í•˜ì—¬ ì§ˆë¬¸ì´ ë” ì–´ë ¤ì›Œì§„ ë²„ì „ì´ì§€ë§Œ, Hugging Faceì—ì„œëŠ” **1.0 ë²„ì „ë§Œ ì œê³µ**ëœë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ 2. \"KorQuAD/squad_kor_v1\" ë°ì´í„°ì…‹ êµ¬ì¡°\n",
        "Hugging Faceì˜ `\"KorQuAD/squad_kor_v1\"`ì€ **SQuAD í˜•ì‹ì„ ë”°ë¥¸ë‹¤**.\n",
        "ë°ì´í„°ëŠ” í¬ê²Œ `train`ê³¼ `validation`ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.\n",
        "\n",
        "#### âœ” ë°ì´í„°ì…‹ í¬ê¸°\n",
        "\n",
        "| ë°ì´í„°ì…‹ | ìƒ˜í”Œ ê°œìˆ˜ |\n",
        "|----------|-----------|\n",
        "| Train (í›ˆë ¨ ë°ì´í„°) | ì•½ 60,407ê°œ |\n",
        "| Validation (ê²€ì¦ ë°ì´í„°) | ì•½ 5,774ê°œ |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ 3. ë°ì´í„°ì…‹ ìƒì„¸ êµ¬ì¡°\n",
        "ê° ë°ì´í„° ìƒ˜í”Œì€ ë‹¤ìŒê³¼ ê°™ì€ í•„ë“œë¥¼ í¬í•¨í•œë‹¤.\n",
        "\n",
        "#### âœ” ë°ì´í„° ì˜ˆì‹œ\n",
        "```\n",
        "{\n",
        "    'id': '654321',  \n",
        "    'title': 'ì„¸ì¢…ëŒ€ì™•',\n",
        "    'context': 'ì„¸ì¢…ëŒ€ì™•ì€ ì¡°ì„ ì˜ ë„¤ ë²ˆì§¸ ì™•ìœ¼ë¡œ, í•œê¸€ì„ ì°½ì œí•œ ê²ƒìœ¼ë¡œ ìœ ëª…í•˜ë‹¤. ê·¸ëŠ” 1397ë…„ì— íƒœì–´ë‚˜ 1418ë…„ì— ì¦‰ìœ„í•˜ì˜€ë‹¤...',\n",
        "    'question': 'ì„¸ì¢…ëŒ€ì™•ì´ ì¦‰ìœ„í•œ ì—°ë„ëŠ”?',\n",
        "    'answers': {'text': ['1418ë…„'], 'answer_start': [50]}\n",
        "}\n",
        "```\n",
        "\n",
        "#### âœ” ê° í•„ë“œ ì„¤ëª…\n",
        "\n",
        "- **id**: ì§ˆë¬¸ ìƒ˜í”Œì˜ ê³ ìœ  ID\n",
        "- **title**: í•´ë‹¹ ë¬¸ë‹¨ì˜ ì œëª©\n",
        "- **context**: ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µì´ í¬í•¨ëœ ë¬¸ë§¥(Paragraph)\n",
        "- **question**: ì£¼ì–´ì§„ `context`ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì§ˆë¬¸\n",
        "- **answers**: ì •ë‹µ (ì •ë‹µ ë¬¸ìì—´ê³¼ í•´ë‹¹ ë¬¸ìì—´ì˜ ì‹œì‘ ìœ„ì¹˜ í¬í•¨)\n",
        "  - `answers[\"text\"]`: ì‹¤ì œ ì •ë‹µ í…ìŠ¤íŠ¸\n",
        "  - `answers[\"answer_start\"]`: `context` ë‚´ì—ì„œ ì •ë‹µì´ ì‹œì‘í•˜ëŠ” ë¬¸ì ì¸ë±ìŠ¤\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ 4. KorQuADë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ \n",
        "**í•œêµ­ì–´ ê¸°ë°˜ QA ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŒ**\n",
        "**Hugging Faceì—ì„œ ì‰½ê²Œ ë¡œë“œ ê°€ëŠ¥**\n",
        "**SQuAD í˜•ì‹ê³¼ ë™ì¼í•˜ì—¬ ê¸°ì¡´ ì˜ì–´ ê¸°ë°˜ ëª¨ë¸ì„ í•œêµ­ì–´ë¡œ ì „ì´ í•™ìŠµí•˜ê¸° ì¢‹ìŒ**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "mbBrgkXeX1lU"
      },
      "id": "mbBrgkXeX1lU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ë¶„ì„ ë° ê³ ì°°**\n",
        "\n",
        "## **BERT ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ìœ **\n",
        "\n",
        "### **1. ì‚¬ì „ í•™ìŠµëœ ê°•ë ¥í•œ ì¸ì½”ë” ê¸°ë°˜ ëª¨ë¸**\n",
        "BERT(Bidirectional Encoder Representations from Transformers)ëŠ” ëŒ€ê·œëª¨ ì½”í¼ìŠ¤ë¥¼ í™œìš©í•œ ì‚¬ì „ í•™ìŠµì„ í†µí•´ ê°•ë ¥í•œ ë¬¸ë§¥ì  ì´í•´ ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìˆë‹¤. ì´ë¥¼ í†µí•´ QA(Task)ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "### **2. ì–‘ë°©í–¥ í•™ìŠµ(Bidirectional Context Learning)**\n",
        "BERTëŠ” ë¬¸ì¥ì˜ ì–‘ë°©í–¥ ë¬¸ë§¥ì„ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ í•™ìŠµí•œë‹¤. ì´ëŠ” ì§ˆë¬¸ê³¼ ë¬¸ë§¥(Context) ê°„ì˜ ê´€ê³„ë¥¼ ë³´ë‹¤ ì •ë°€í•˜ê²Œ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ëœë‹¤.\n",
        "\n",
        "### **3. í† í° ìˆ˜ì¤€ì˜ ì •ë°€í•œ ìœ„ì¹˜ ì˜ˆì¸¡**\n",
        "KorQuADì™€ ê°™ì€ MRC(Task)ì—ì„œëŠ” ì •ë‹µì˜ ì‹œì‘ê³¼ ë ìœ„ì¹˜ë¥¼ ì˜ˆì¸¡í•´ì•¼ í•œë‹¤. BERTëŠ” ê° í† í°ì˜ í‘œí˜„ì„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•˜ë©°, ì´ë¥¼ í†µí•´ ë†’ì€ ì •í™•ë„ë¡œ ì •ë‹µì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ë‚¼ ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "### **4. ì‚¬ì „ í•™ìŠµ + íŒŒì¸íŠœë‹ êµ¬ì¡°**\n",
        "BERTëŠ” ì´ë¯¸ ë°©ëŒ€í•œ ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµëœ ìƒíƒœì—ì„œ ì œê³µë˜ë¯€ë¡œ, íŠ¹ì • ë„ë©”ì¸(ì˜ˆ: í•œêµ­ì–´ QA)ì—ì„œ ì ì€ ì–‘ì˜ ë°ì´í„°ë¡œë„ íš¨ê³¼ì ì¸ íŒŒì¸íŠœë‹ì´ ê°€ëŠ¥í•˜ë‹¤.\n",
        "\n",
        "### **5. í•œêµ­ì–´ ì§€ì› ëª¨ë¸(KLUE-BERT)ì˜ ì¡´ì¬**\n",
        "KorQuAD ë°ì´í„°ì…‹ì„ í™œìš©í•˜ë ¤ë©´ í•œêµ­ì–´ì— íŠ¹í™”ëœ ëª¨ë¸ì´ í•„ìš”í•˜ë‹¤. KLUE-BERTëŠ” í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬(NLP)ë¥¼ ìœ„í•´ ìµœì í™”ëœ ëª¨ë¸ë¡œ, KorQuAD íƒœìŠ¤í¬ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## **ì‹¤í—˜ ê²°ê³¼ ë¶„ì„**\n",
        "\n",
        "### **1. í•™ìŠµ ì§„í–‰ ê³¼ì •**\n",
        "- í•™ìŠµ ì´ˆê¸° ë¶€í„°, pre_trained ëª¨ë¸ì´ ë„ˆë¬´ ì˜ ë§Œë“¤ì–´ ì¡ŒëŠ”ì§€, ì¢‹ì€ ì„±ëŠ¥ì„ ë³¼ ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "### **2. í‰ê°€ ê²°ê³¼ (Evaluation Results)**\n",
        "- ëª¨ë¸ì´ ë‹¨ìˆœí•œ ì§ˆë¬¸ë¿ë§Œ ì•„ë‹ˆë¼, ë³µì¡í•œ ì§ˆë¬¸ì—ì„œë„ ì–´ëŠ ì •ë„ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ê°–ì¶”ì—ˆìŒì„ í™•ì¸í•˜ë©°, loss curve ë˜í•œ ì˜ ë–¨ì–´ì§ì„ í™•ì¸.\n",
        "\n",
        "---\n",
        "\n",
        "## **í•œê³„ì  ë° ê°œì„  ë°©í–¥**\n",
        "\n",
        "### **1. Answer ìƒì„± ë¬¸ì œ**\n",
        "- ìš°ë¦¬ ëª¨ë¸ì€ ê¸°ì¡´ì˜ ì •ë³´ë¥¼ ê¸°ì–µí•˜ê±°ë‚˜, í•™ìŠµí•˜ë ¤ëŠ” ì‹œë„ë¥¼ ì „í˜€ í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—\n",
        "content ë§¥ë½ì˜ ì—¬ë¶€ì— í¬ê²Œ ì˜ì¡´í•œë‹¤.\n",
        "\n",
        "### **2. ì¶”ë¡  ë¬¸ì œ **\n",
        "- BERT ê¸°ë°˜ ëª¨ë¸ì€ ì „í˜€ ìƒì„±í•˜ì§€ ì•Šê³ , ë‹¨ìˆœíˆ context ë‚´ì˜ ì–´ëŠ ë¶€ë¶„ì´ ê°€ì¥ ì¤‘ìš”í•œì§€ ì—¬ë¶€ë¥¼ í†µí•´ ì‹œì‘ê³¼ ëì ì„ íƒìƒ‰í•˜ëŠ” ê²ƒì´ ì „ë¶€ì´ë‹¤. ì¦‰ ê·¸ë ‡ê¸°ì— ì•„ì˜ˆ contextì—ì„œ ì¶”ì¸¡í•´ì•¼ í•˜ëŠ” ì–´ë ¤ìš´ ë¬¸ì œì˜ ê²½ìš°ëŠ” ì í•©í•œ ë‹µì„ ì´ëŒì–´ë‚´ì§€ ëª»í•œë‹¤.\n",
        "---\n",
        "\n",
        "## **ê²°ë¡ **\n",
        "ë³¸ ì‹¤í—˜ì„ í†µí•´ KLUE-BERT ëª¨ë¸ì´ KorQuAD ë°ì´í„°ì…‹ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµë  ìˆ˜ ìˆìŒì„ í™•ì¸í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ, Encoder ê¸°ë°˜ì˜ ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— í•­ìƒ Context ë‚´ì— ì •ë‹µì´ ìˆìŒì„ ë³´ì¥í•´ì•¼ í•œë‹¤ëŠ” ë¬¸ì œê°€ ìˆë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ í•œêµ­ì–´ QA ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ë³´ë‹¤ ë„“ì€ ë²”ìœ„ì˜ ì§ˆì˜ì‘ë‹µ íƒœìŠ¤í¬ì— ì ìš©í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.\n"
      ],
      "metadata": {
        "id": "Eh61mQMIqBLr"
      },
      "id": "Eh61mQMIqBLr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **íŠ¹ì´ì‚¬í•­**  \n",
        "\n",
        "ë‚´ê°€ ì‹œë„í•´ë³¸ ì ‘ê·¼ ë°©ì‹ì€ ì´ ë‘ ê°€ì§€ë‹¤.  \n",
        "\n",
        "1. **BERT ê¸°ë°˜ ëª¨ë¸ì„ ì´ìš©í•´ ì‹œì‘(Start), ë(End) í† í° ìœ„ì¹˜ ì°¾ê¸°**  \n",
        "2. **Decoder ê¸°ë°˜ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì •ë‹µì„ ì§ì ‘ ìƒì„±í•˜ê¸°**  \n",
        "\n",
        "ê²°ê³¼ì ìœ¼ë¡œ 1ë²ˆ ë°©ë²•ì„ ì„ íƒí•˜ì—¬ ê³¼ì œë¥¼ ì œì¶œí–ˆëŠ”ë°, ë‘ ë°©ë²•ì˜ ì¥ë‹¨ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.  \n",
        "\n",
        "---\n",
        "\n",
        "## **1ë²ˆ ë°©ë²•: BERT ê¸°ë°˜ í† í° ìœ„ì¹˜ ì˜ˆì¸¡**  \n",
        "\n",
        "### **ì¥ì **  \n",
        "- **í•™ìŠµì´ ë¹„êµì  ë¹ ë¦„** â†’ ì‚¬ì „ í•™ìŠµëœ BERT ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ê¸° ë•Œë¬¸ì— í•™ìŠµ ì†ë„ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë¹ ë¥´ë‹¤.  \n",
        "- **ê°„í¸í•œ êµ¬í˜„** â†’ Hugging Faceì—ì„œ `AutoModelForQuestionAnswering`ì„ ì œê³µí•˜ë¯€ë¡œ ë³„ë„ì˜ Headë¥¼ ì§ì ‘ êµ¬ì„±í•  í•„ìš” ì—†ì´ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš©í•˜ë©´ ëœë‹¤.  \n",
        "- **ì •í™•í•œ ì •ë‹µì„ ì˜ˆì¸¡** â†’ ì •ë‹µì´ `context` ë‚´ì— ì¡´ì¬í•˜ê¸°ë§Œ í•˜ë©´, ë†’ì€ ì •í™•ë„ë¡œ ì •ë‹µ ìœ„ì¹˜ë¥¼ ì°¾ì•„ë‚¼ ìˆ˜ ìˆë‹¤.  \n",
        "\n",
        "### **ë‹¨ì **  \n",
        "- **Context ì˜ì¡´ì„±ì´ ë†’ìŒ** â†’ ì •ë‹µì„ ì°¾ê¸° ìœ„í•´ ë°˜ë“œì‹œ `context`ê°€ ì£¼ì–´ì ¸ì•¼ í•˜ë©°, `context` ì—†ì´ ë‹¨ë… ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•  ìˆ˜ ì—†ë‹¤.  \n",
        "- **ì¶”ë¡ ì´ ì œí•œì ** â†’ ì§ˆë¬¸ì´ ë³µì¡í•˜ê±°ë‚˜ `context` ë‚´ì—ì„œ ëª…í™•í•œ ì •ë‹µì„ ì°¾ê¸° ì–´ë ¤ìš´ ê²½ìš° ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆë‹¤.  \n",
        "- **ì •í™•í•œ ìœ„ì¹˜ ì˜ˆì¸¡ì´ í•„ìš”** â†’ ì •ë‹µì˜ ì‹œì‘ê³¼ ë ìœ„ì¹˜ë¥¼ ì˜ëª» ì˜ˆì¸¡í•˜ë©´ ë‹µë³€ì´ ë¶€ì •í™•í•´ì§ˆ ìˆ˜ ìˆë‹¤.  \n",
        "\n",
        "---\n",
        "\n",
        "## **2ë²ˆ ë°©ë²•: Decoder ê¸°ë°˜ ìƒì„± ëª¨ë¸**  \n",
        "\n",
        "### **ì¥ì **  \n",
        "- **Context ì—†ì´ë„ ë‹µë³€ ê°€ëŠ¥** â†’ ì •ë‹µì´ `context`ì— í¬í•¨ë˜ì§€ ì•Šë”ë¼ë„, ëª¨ë¸ì´ ìƒˆë¡œìš´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.  \n",
        "- **ë³´ë‹¤ ìœ ì—°í•œ ì§ˆì˜ì‘ë‹µ** â†’ ë‹¨ìˆœí•œ `Span Extraction` ë°©ì‹ì´ ì•„ë‹ˆë¼, ì—´ë¦° ë„ë©”ì¸ì˜ ì§ˆë¬¸ì—ë„ ë‹µí•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ ìˆë‹¤.  \n",
        "\n",
        "### **ë‹¨ì **  \n",
        "- **í•™ìŠµì´ ì˜¤ë˜ ê±¸ë¦¼** â†’ ìƒì„± ëª¨ë¸(ì˜ˆ: T5, GPT)ì€ ì¼ë°˜ì ìœ¼ë¡œ í•™ìŠµ íŒŒë¼ë¯¸í„°ê°€ ë§ì•„, íŒŒì¸íŠœë‹ ì‹œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤.  \n",
        "- **ì •í™•ì„± ë¬¸ì œ** â†’ `context`ì— ì •ë‹µì´ ì¡´ì¬í•¨ì—ë„ ë¶ˆêµ¬í•˜ê³ , ìƒì„± ê³¼ì •ì—ì„œ ì˜ëª»ëœ ë‹µë³€ì„ ë§Œë“¤ì–´ë‚¼ ê°€ëŠ¥ì„±ì´ ìˆë‹¤.  \n",
        "- **ì¶”ë¡  ì†ë„ê°€ ëŠë¦¼** â†’ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ë””ì½”ë”©ì´ í•„ìš”í•˜ë¯€ë¡œ, `Span Extraction` ë°©ì‹ë³´ë‹¤ ì¶”ë¡  ì†ë„ê°€ ëŠë¦¬ë‹¤.  \n",
        "\n",
        "---\n",
        "\n",
        "## **ê²°ë¡  ë° ì„ íƒ ì´ìœ **  \n",
        "\n",
        "BERT ê¸°ë°˜ì˜ **í† í° ìœ„ì¹˜ ì˜ˆì¸¡ ë°©ì‹(1ë²ˆ)**ì„ ì„ íƒí•œ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.  \n",
        "\n",
        "1. **íš¨ìœ¨ì ì¸ í•™ìŠµ** â†’ ì œí•œëœ ì‹œê°„ ë‚´ì— ìµœì ì˜ ì„±ëŠ¥ì„ ë‚´ê¸° ìœ„í•´ í•™ìŠµ ì†ë„ê°€ ë¹ ë¥¸ ëª¨ë¸ì„ ì„ íƒí•´ì•¼ í–ˆë‹¤.  \n",
        "2. **Hugging Face ì§€ì›** â†’ ì´ë¯¸ ì œê³µë˜ëŠ” QA ëª¨ë¸ êµ¬ì¡°ë¥¼ í™œìš©í•˜ë©´, ëª¨ë¸ êµ¬ì¡°ë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•Šê³  ë¹ ë¥´ê²Œ ì ìš©í•  ìˆ˜ ìˆì—ˆë‹¤.  \n",
        "3. **ë†’ì€ ì‹ ë¢°ì„±** â†’ ì •ë‹µì´ `context`ì— í¬í•¨ë˜ì–´ ìˆê¸°ë§Œ í•˜ë©´, ë¹„êµì  ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.  \n",
        "4. **ì¶”ë¡  ì†ë„** â†’ ìƒì„± ëª¨ë¸ë³´ë‹¤ ë¹ ë¥´ê²Œ ì˜ˆì¸¡í•  ìˆ˜ ìˆì–´ ì‹¤ì œ ì‘ìš©ì—ë„ ì í•©í–ˆë‹¤.\n",
        "\n",
        "ë”ë¶ˆì–´ DLPC í™˜ê²½ì—ì„œì˜ Decoder ê¸°ë°˜ì˜ ëª¨ë¸ ê°™ì´ í° ëª¨ë¸ì„ í•™ìŠµí•˜ê¸°ì—ëŠ” ì¤‘ê°„ì— í•™ìŠµì´ ì¢…ë£Œë˜ì–´ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ëŒë ¤ì•¼ í•œë‹¤ëŠ” ë“± ì œì•½ì‚¬í•­ì´ ë§ì•„ì„œ ê²°êµ­ BERT ê¸°ë°˜ì˜ ëª¨ë¸ë¡œ ì œì¶œí•˜ê²Œ ë˜ì—ˆë‹¤.\n",
        "\n",
        "í•˜ì§€ë§Œ, ì—´ë¦° ë„ë©”ì¸ ì§ˆë¬¸(ì˜ˆ: `\"ì„¸ê³„ì—ì„œ ê°€ì¥ ë†’ì€ ì‚°ì€?\"`)ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê²ƒì€ BERT ê¸°ë°˜ ëª¨ë¸ë¡œëŠ” ì–´ë ¤ì› ë‹¤. ë”°ë¼ì„œ, ë§Œì•½ íŠ¹ì • ë„ë©”ì¸ì— í•œì •ë˜ì§€ ì•Šì€ QA ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ì•¼ í•œë‹¤ë©´, **Decoder ê¸°ë°˜ ëª¨ë¸**ì„ ê³ ë ¤í•  í•„ìš”ê°€ ìˆë‹¤ê³  ìƒê°í•œë‹¤.\n",
        "\n"
      ],
      "metadata": {
        "id": "KEsQ4SRPsblZ"
      },
      "id": "KEsQ4SRPsblZ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}